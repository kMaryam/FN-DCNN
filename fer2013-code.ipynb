{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","**Import the necessary librairies**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","import numpy as np\n","import pandas as pd \n","import os\n","import sys\n","import cv2\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random\n","import pickle\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","import tensorflow.keras as keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","from multiprocessing import Queue\n","from keras.utils import to_categorical\n","from tensorflow.keras.losses import categorical_crossentropy\n","from keras.utils import plot_model\n","import seaborn as sns\n","from sklearn.preprocessing import label_binarize\n","from sklearn.metrics import roc_curve, auc\n","from IPython.display import HTML\n","from keras.applications import ResNet50"]},{"cell_type":"markdown","metadata":{},"source":["**Import Fer2013 dataset and Display Class Distribution**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["root_path = '/kaggle/input/fer_2013/fer/'\n","class_names = sorted(os.listdir(root_path))\n","n_classes = len(class_names)\n","\n","# Class Distribution\n","class_dis = [len(os.listdir(root_path + name)) for name in class_names]\n","\n","# Show\n","print(f\"Total Number of Classes : {n_classes} \\nClass Names : {class_names}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Pre-processing step**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DATADIR = '/kaggle/input/fer_2013/fer/'\n","\n","CATEGORIES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sadness', 'surprise']\n","\n","for category in CATEGORIES:  \n","    path = os.path.join(DATADIR,category)  \n","    for img in os.listdir(path):  \n","        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n","        plt.imshow(img_array, cmap='gray')  # graph it\n","        plt.show()  # display!\n","        print(img_array)\n","        print(img_array.shape)\n","        break  \n","    break "]},{"cell_type":"markdown","metadata":{},"source":["**Creating training Data**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["IMG_SIZE = 48\n","training_data = []\n","\n","def create_training_data():\n","    for category in CATEGORIES:  \n","\n","        path = os.path.join(DATADIR,category)  \n","        class_num = CATEGORIES.index(category)  \n","\n","        for img in tqdm(os.listdir(path)):  \n","            try:\n","                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n","                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n","                training_data.append([new_array, class_num])  # add this to the training data\n","            except Exception as e:  \n","                pass\n","            #except OSError as e:\n","            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n","            #except Exception as e:\n","            #    print(\"general exception\", e, os.path.join(path,img))\n","\n","create_training_data()\n","\n","print(len(training_data))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["random.shuffle(training_data)\n","A2= []\n","B2= []\n","for features,label in training_data:\n","    A2.append(features)\n","    B2.append(label)\n","\n","print(A2[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n","\n","A2= np.array(A2).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n","\n","pickle_out = open(\"A2.pickle\",\"wb\")\n","pickle.dump(A2, pickle_out)\n","pickle_out.close()\n","\n","pickle_out = open(\"B2.pickle\",\"wb\")\n","pickle.dump(B2, pickle_out)\n","pickle_out.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle_in = open(\"A2.pickle\",\"rb\")\n","A2 = pickle.load(pickle_in)\n","pickle_in = open(\"B2.pickle\",\"rb\")\n","B2= pickle.load(pickle_in)\n","B2 = to_categorical(B2, num_classes=7)\n","x_train,x_valid,y_train,y_valid=train_test_split(A2,B2,test_size=0.2)\n","x_train = x_train / 255.\n","x_valid = x_valid / 255.\n","num_classes=y_train.shape[1]"]},{"cell_type":"markdown","metadata":{},"source":["**Building the deeep convolutional neural network**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def build_network(optim):\n","   \n","\n","    network = Sequential(name='Deep_CNN')\n","\n","    network.add(\n","        Conv2D(\n","            filters=64,\n","            kernel_size=(5,5),\n","            input_shape=(48, 48, 1),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_1'))\n","    network.add(\n","        Conv2D(\n","            filters=64,\n","            kernel_size=(5,5),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_2'))\n","    \n","    network.add(MaxPooling2D(pool_size=(2,2), name='maxpooling2d_1'))\n","    network.add(Dropout(0.4, name='dropout_1'))\n","\n","    network.add(\n","        Conv2D(\n","            filters=128,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_3'))\n","    network.add(\n","        Conv2D(\n","            filters=128,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_4'))\n","    \n","    network.add(MaxPooling2D(pool_size=(2,2), name='maxpooling2d_2'))\n","    network.add(Dropout(0.4, name='dropout_2'))\n","\n","    network.add(\n","        Conv2D(\n","            filters=256,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_5'))\n","    network.add(\n","        Conv2D(\n","            filters=256,\n","            kernel_size=(3,3),\n","            activation='elu',\n","            padding='same',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_6'))\n","    \n","    network.add(MaxPooling2D(pool_size=(2,2), name='maxpooling2d_3'))\n","    network.add(Dropout(0.5, name='dropout_3'))\n","\n","    network.add(Flatten(name='flatten'))\n","        \n","    network.add(\n","        Dense(\n","            128,\n","            activation='elu',\n","            kernel_initializer='he_normal'\n","        )\n","    )\n","    network.add(BatchNormalization(name='batchnormalization_7'))\n","    \n","    network.add(Dropout(0.6, name='dropout_4'))\n","    \n","    network.add(\n","        Dense(\n","            num_classes,\n","            activation='softmax',\n","            name='out_layer'\n","        )\n","    )\n","    METRICS = [\n","        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall'),\n","        tf.keras.metrics.AUC(name='auc')\n","    ]\n","    network.compile(\n","        loss='categorical_crossentropy',\n","        optim=optim,\n","        metrics= METRICS \n","    )\n","    \n","    network.summary()\n","    \n","    return network\n","\n","early_stopping = EarlyStopping(\n","    monitor='val_accuracy',\n","    min_delta=0.00005,\n","    patience=11,\n","    verbose=1,\n","    restore_best_weights=True,\n",")\n","\n","lr_scheduler = ReduceLROnPlateau(\n","    monitor='val_accuracy',\n","    factor=0.5,\n","    patience=7,\n","    min_lr=1e-7,\n","    verbose=1,\n",")\n","\n","callbacks = [\n","    early_stopping,\n","    lr_scheduler,\n","]\n","batch_size = 32 #batch size of 32 performs the best.\n","epochs = 100\n","optims= keras.optims.SGD(lr=0.001, momentum=0.9)\n","\n","model = build_network(optims) \n","\n","train_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.15,\n","    height_shift_range=0.15,\n","    shear_range=0.15,\n","    zoom_range=0.15,\n","    horizontal_flip=True,  # set each sample mean to 0\n","    zca_whitening=False,  # apply ZCA whitening\n","   \n",")\n","\n","# Plot the model architecture\n","plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n","train_datagen.fit(x_train)\n","\n","history = model.fit(\n","        train_datagen.flow(x_train, y_train, batch_size=batch_size),\n","        validation_data=(x_valid, y_valid),\n","        steps_per_epoch=len(x_train) / batch_size,\n","        epochs=epochs,\n","        callbacks=callbacks,)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Builiding RESNET50\n","\n","IMG_WIDTH=48\n","IMG_HEIGHT=48\n","CHANNELS=3\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH,IMG_HEIGHT , CHANNELS))\n","\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","base_model.summary()\n","model = models.Sequential()\n","model.add(base_model)\n","model.add(layers.GlobalAveragePooling2D())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(7, activation='softmax'))  # 7 classes for facial expressions\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy',\n","        optimizer=optims[1],\n","        metrics=['accuracy'])\n","\n","# Save the best model during training\n","checkpoint = ModelCheckpoint('emotion_resnet_model.h5', save_best_only=True)\n","\n","# Train the model\n","history = model.fit(\n","        x_train, y_train, batch_size=batch_size,\n","        validation_data=(x_valid, y_valid),\n","        steps_per_epoch=len(x_train) / batch_size,\n","        epochs=epochs,\n","        callbacks=[checkpoint]\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["**Displaying the results**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.set()\n","fig = pyplot.figure(0, (12, 4))\n","\n","ax = pyplot.subplot(1, 2, 1)\n","sns.lineplot(x=history.epoch,y=history.history['accuracy'], label='train')\n","sns.lineplot(x=history.epoch,y=history.history['val_accuracy'], label='valid')\n","pyplot.title('Accuracy')\n","pyplot.tight_layout()\n","\n","ax = pyplot.subplot(1, 2, 2)\n","sns.lineplot(x=history.epoch,y= history.history['loss'], label='train')\n","sns.lineplot(x=history.epoch,y= history.history['val_loss'], label='valid')\n","pyplot.title('Loss')\n","pyplot.tight_layout()\n","pyplot.savefig('epoch_history_dnn.png')\n","pyplot.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'total wrong validation predictions: {np.sum(y_valid) != predicted_classes}\\n\\n')\n","print(classification_report(true_classes,predicted_classes))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_evalation = model.evaluate(x_train, y_train)\n","test_evaluation = model.evaluate(x_valid, y_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metric_list = [\"Loss\",\"Accuracy\", \"Precision\", \"Recall\", \"Auc\", \"F1_Score\"]\n","\n","df = pd.DataFrame(list(zip(metric_list, \n","                           [round(num, 3) for num in train_evalation], \n","                           [round(num, 3) for num in test_evaluation])),\n","                  columns=['Metric Name', 'Train', 'Validate'])\n","\n","print('\\n\\nModel Scores\\n')\n","\n","HTML(df.to_html(escape=False))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","y_test_bin = label_binarize(y_valid, classes=np.arange(7))\n","#X_train, X_valid, y_train, y_valid\n","y_score = model.predict(x_valid)\n","\n","for i in range(7):\n","    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plot the ROC curve for each class\n","plt.figure(figsize=(8, 6))\n","\n","for i in range(7):\n","    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n","\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--', linewidth=2)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve for Multi-class Classification')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","plt.savefig('roc_dnn')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
